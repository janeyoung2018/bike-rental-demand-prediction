{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Xf3TUbRzZC"
   },
   "source": [
    "# Exploratory Data Analysis â€” Bike Sharing Dataset\n",
    "\n",
    "**Goal**: Understand patterns in hourly bike rentals (`cnt`) to support building a daily prediction service model for planning processes and bicycle logistics.\n",
    "\n",
    "Dataset source: [UCI Bike Sharing Dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFXkbXzxWzB5"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from utils_nb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_show_fig(fig, title):\n",
    "    \"\"\"Helper function to create and show figures with consistent layout.\"\"\"\n",
    "    fig.update_layout(width=600, height=350, title=title)  # Set figure size here\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h-IGsR9UVow"
   },
   "source": [
    "---\n",
    "## 1. Load & Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "sS4VjfTHRwGi",
    "outputId": "544525db-32c6-426f-edc6-9a2b3d21a81f"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/hour.csv\")  # 'hour.csv' is the hourly dataset\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data status, columns, dtypes, non-null count\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5Lb-8UEWiUN"
   },
   "source": [
    "## 2. Basic Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwiqT9VvQnIH"
   },
   "source": [
    "### 2.1. Convert 'dteday' to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1szcaK_QeHw"
   },
   "outputs": [],
   "source": [
    "# Convert date column\n",
    "df['dteday'] = pd.to_datetime(df['dteday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqEe6NM_QmiH"
   },
   "source": [
    "### 2.2. Check  missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Sb2ZgxJRWPp",
    "outputId": "adc2dfb7-15e9-4cc5-dc10-165066b45495"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().values.any()\n",
    "print(f\"Missing values in dataset: {missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-RhQEPEQsNB"
   },
   "source": [
    "### 2.3 Check Dataset Coverage & Completeness\n",
    "- A few days contain fewer than 24 records, indicating data incompleteness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSh2erveR3Sz",
    "outputId": "ed82c991-7e90-49ec-9a16-8847e47b2def"
   },
   "outputs": [],
   "source": [
    "# Check the overall date coverage\n",
    "print(\"Date Range:\")\n",
    "print(f\"Start: {df['dteday'].min().date()}  |  End: {df['dteday'].max().date()}\")\n",
    "\n",
    "# Count number of unique days\n",
    "num_days = df['dteday'].nunique()\n",
    "print(f\"Total unique days: {num_days}\")\n",
    "\n",
    "# Show available years\n",
    "years = df['dteday'].dt.year.unique()\n",
    "print(f\"Years in dataset: {sorted(years)}\")\n",
    "\n",
    "# Check how many records per day (should be 24 ideally)\n",
    "daily_record_unique_counts = df.groupby('dteday')['instant'].count().value_counts()\n",
    "print(\"\\nUnique records per day:\")\n",
    "print(daily_record_unique_counts)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check duplicates dates and hours\n",
    "dupli_num = df.duplicated(subset=['dteday', 'hr'], keep='last').shape[0] - df.shape[0]\n",
    "print(f\"Duplicated records number: {dupli_num}\")\n",
    "\n",
    "# Check cnt=0 records\n",
    "zero_cnt_num = df[df['cnt'] == 0].shape[0]\n",
    "print(f\"Zero cnt records number: {zero_cnt_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "nlyP9z6_XGYb",
    "outputId": "6aa26e89-d43e-4046-ece3-61e5df8906d7"
   },
   "outputs": [],
   "source": [
    "# Clean and fill missing hours\n",
    "df_cleaned = fill_missing_hours(df)\n",
    "\n",
    "# Confirm daily completeness\n",
    "assert all(df_cleaned.groupby('dteday')['cnt'].count() == 24)\n",
    "\n",
    "# Confirm no nulls left\n",
    "print(df_cleaned.isnull().any().any())\n",
    "\n",
    "# Preview cleaned data\n",
    "df_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Statistics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "F4-15pCZZhin",
    "outputId": "82b85ba9-d795-45e6-eac2-b00adec2d9ff"
   },
   "outputs": [],
   "source": [
    "# Target Variable (cnt)\n",
    "fig_cnt_density = px.histogram(df_cleaned, x='cnt', marginal='rug', title = f'Distribution & Density plot of cnt')\n",
    "fig_cnt_box = px.box(df_cleaned, y=\"cnt\", title=\"Box plot of cnt\")\n",
    "create_and_show_fig(fig_cnt_density, 'Distribution & Density plot of cnt')\n",
    "create_and_show_fig(fig_cnt_box, title=\"Box plot of cnt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tB59ntMDb-Lq"
   },
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "for feature in numerical_features:\n",
    "    fig_box = px.box(df_cleaned, y=feature, title=f\"Box plot of {feature}\")\n",
    "    fig_density = px.histogram(df_cleaned, x=feature, marginal='rug', title = f'Distribution & Density plot of {feature}')\n",
    "    create_and_show_fig(fig_density, f\"Distribution & Density plot of {feature}\")\n",
    "    create_and_show_fig(fig_box, f\"Box plot of {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Features\n",
    "# The distribution of ['season', 'yr', 'mnth', 'hr', 'weekday'] is straightforward, ignore here\n",
    "categorical_features =  ['workingday', 'weathersit']\n",
    "for feature in categorical_features:\n",
    "    fig_bar = px.bar(df_cleaned[feature].value_counts().sort_index(), title=f\"Count of {feature}\")\n",
    "    create_and_show_fig(fig_bar, f\"Count of {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Bivariate Analysis\n",
    "# Target vs. Numerical\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "for feature in numerical_features:\n",
    "    fig_scatter = px.scatter(df_cleaned, x=feature, y=\"cnt\", title=f\"cnt vs. {feature}\")\n",
    "    create_and_show_fig(fig_scatter, f\"cnt vs. {feature}\")\n",
    "\n",
    "fig_line_hr = px.line(df_cleaned.groupby('hr')['cnt'].mean().reset_index(), x='hr', y='cnt', title = 'Mean cnt by hour')\n",
    "create_and_show_fig(fig_line_hr, 'Mean cnt by hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target vs. Categorical\n",
    "categorical_features = ['season', 'yr', 'mnth', 'weekday', 'workingday', 'weathersit']\n",
    "for feature in categorical_features:\n",
    "    fig_box_cat = px.box(df_cleaned, x=feature, y=\"cnt\", title=f\"cnt vs. {feature}\")\n",
    "    create_and_show_fig(fig_box_cat, f\"cnt vs. {feature}\")\n",
    "    fig_bar_mean = px.bar(df_cleaned.groupby(feature)['cnt'].mean(), title = f'Mean cnt by {feature}')\n",
    "    create_and_show_fig(fig_bar_mean, f'Mean cnt by {feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "correlation_matrix = df_cleaned[numerical_features + ['cnt']].corr()\n",
    "fig_heatmap = px.imshow(correlation_matrix, title=\"Correlation Matrix\")\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Time Series Analysis\n",
    "fig_time_series = px.line(df_cleaned, x='dteday', y='cnt', title='cnt over time')\n",
    "create_and_show_fig(fig_time_series, \"cnt over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['dteday'] = pd.to_datetime(df_cleaned['dteday'])\n",
    "# Use resample to set the frequency and aggregate to daily sums\n",
    "daily_cnt = df_cleaned.set_index('dteday')['cnt'].resample('D').sum() #set index, and resample.\n",
    "\n",
    "# Seasonal Decomposition\n",
    "decomposition = seasonal_decompose(daily_cnt, model=\"additive\", period=30)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "# Plotting the Decomposition\n",
    "fig_original = px.line(x=daily_cnt.index, y=daily_cnt, title=\"Original Time Series\")\n",
    "create_and_show_fig(fig_original, \"Original Time Series\")\n",
    "\n",
    "fig_trend = px.line(x=trend.index, y=trend, title=\"Trend Component\")\n",
    "create_and_show_fig(fig_trend, \"Trend Component\")\n",
    "\n",
    "fig_seasonal = px.line(x=seasonal.index, y=seasonal, title=\"Seasonal Component\")\n",
    "create_and_show_fig(fig_seasonal, \"Seasonal Component\")\n",
    "\n",
    "fig_residual = px.line(x=residual.index, y=residual, title=\"Residual Component\")\n",
    "create_and_show_fig(fig_residual, \"Residual Component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ACF plot\n",
    "plt.subplot(211)\n",
    "plot_acf(daily_cnt, lags=730, ax=plt.gca()) #lags set to 365, to show a years worth of data.\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "\n",
    "# PACF plot\n",
    "plt.subplot(212)\n",
    "plot_pacf(daily_cnt, lags=365,ax=plt.gca()) #lags set to 30, to show a month worth of data.\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_cnt = df_cleaned.groupby(\"datetime\").cnt.sum()\n",
    "\n",
    "# Apply Differencing\n",
    "hourly_diff = hourly_cnt.diff(24).dropna()\n",
    "\n",
    "check_stationarity(hourly_cnt)\n",
    "check_stationarity(hourly_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ACF plot\n",
    "plt.subplot(211)\n",
    "plot_acf(hourly_cnt, lags=24, ax=plt.gca()) #lags set to 365, to show a years worth of data.\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "\n",
    "# PACF plot\n",
    "plt.subplot(212)\n",
    "plot_pacf(hourly_cnt, lags=24,ax=plt.gca()) #lags set to 30, to show a month worth of data.\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF using Plotly\n",
    "\n",
    "plot_acf_pacf_plotly(hourly_cnt, lags=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF using Plotly\n",
    "\n",
    "plot_acf_pacf_plotly(hourly_diff, lags=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weeks = [\n",
    "    (\"2012-08-01\", \"2012-08-07\"),\n",
    "    (\"2012-12-25\", \"2012-12-31\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all models\n",
    "baseline_df = evaluate_baseline(hourly_cnt, test_weeks)\n",
    "arima_df = evaluate_arima(hourly_cnt, test_weeks)\n",
    "xgb_df = evaluate_xgboost_weekly(df_cleaned, test_weeks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([arima_df, xgb_df,baseline_df])\n",
    "results = label_test_period(results, test_weeks)\n",
    "results['date'] = pd.to_datetime(results['date'])\n",
    "results = results.sort_values(by=[\"model\", \"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Get the unique test periods\n",
    "test_periods = results['test_period'].unique()\n",
    "\n",
    "model_colors = {\n",
    "    'ARIMA': '#636EFA',\n",
    "    'Baseline': '#EF553B',\n",
    "    'XGBoost': '#00CC96'\n",
    "}\n",
    "\n",
    "# Create subplots (1 row per test week)\n",
    "fig = make_subplots(\n",
    "    rows=len(test_periods),\n",
    "    cols=1,\n",
    "    shared_xaxes=False,\n",
    "    subplot_titles=test_periods\n",
    ")\n",
    "\n",
    "for i, period in enumerate(test_periods):\n",
    "    df_sub = results[results['test_period'] == period]\n",
    "    models = df_sub['model'].unique()\n",
    "\n",
    "    for model in models:\n",
    "        df_model = df_sub[df_sub['model'] == model]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_model['date'],\n",
    "                y=df_model['mae'],\n",
    "                mode='lines+markers',\n",
    "                name=model,\n",
    "                legendgroup=model,\n",
    "                showlegend=(i == 0),  # only show legend once\n",
    "                line=dict(color=model_colors.get(model, 'gray'))  # << add this\n",
    "            ),\n",
    "            row=i+1,\n",
    "            col=1\n",
    "        )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=500 * len(test_periods),\n",
    "    title_text=\"Model MAE Over Selected Test Weeks (Separate X-Axis)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"MAE\",\n",
    "    legend_title=\"Model\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickformat=\"%b %d\", tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_csv(\"../data/pred_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.groupby(\"dteday\").apply(lambda x: mean_absolute_error(x[\"cnt\"], x['cnt_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean MAE per model\n",
    "print(results.groupby('model')['mae'].mean().round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split to Train and Test\n",
    "train_size = int(len(hourly_cnt) * 0.8)\n",
    "train, test = hourly_cnt[:train_size], hourly_cnt[train_size:]\n",
    "\n",
    "# 3. Apply Seasonal Differencing\n",
    "seasonal_lag = 24\n",
    "train_diff = train.diff(seasonal_lag).dropna()\n",
    "check_stationarity(train_diff)\n",
    "\n",
    "# 4. Fit SARIMA Model (Example)\n",
    "model = ARIMA(train_diff, order=(2, 0, 3))\n",
    "results = model.fit()\n",
    "\n",
    "# 5. Forecast Train and Test\n",
    "train_forecast_diff = results.fittedvalues\n",
    "test_forecast_diff = results.forecast(steps=len(test))\n",
    "\n",
    "# 6. Inverse Transformation for Train\n",
    "train_forecast_original = pd.Series(index=train_diff.index)\n",
    "\n",
    "# Initialize the first 24 values\n",
    "for i in range(seasonal_lag):\n",
    "    train_forecast_original[train_diff.index[i]] = train[train_diff.index[i]]\n",
    "\n",
    "# Inverse transform the rest of the values\n",
    "for i in range(seasonal_lag, len(train_diff)):\n",
    "    train_forecast_original[train_diff.index[i]] = train_forecast_original[train_diff.index[i - seasonal_lag]] + train_forecast_diff[i-seasonal_lag]\n",
    "\n",
    "# 7. Inverse Transformation for Test\n",
    "test_forecast_original = pd.Series(index=test.index)\n",
    "\n",
    "# Initialize the first 24 values using the last 24 values from train\n",
    "for i in range(seasonal_lag):\n",
    "    test_forecast_original[test.index[i]] = train[-seasonal_lag + i] + test_forecast_diff[i]\n",
    "\n",
    "# Inverse transform the rest of the values\n",
    "for i in range(seasonal_lag, len(test_forecast_diff)):\n",
    "    test_forecast_original[test.index[i]] = test_forecast_original[test.index[i - seasonal_lag]] + test_forecast_diff[i]\n",
    "\n",
    "# 8. Plot Train and Test Predictions\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(train, label='Train Data')\n",
    "plt.plot(train_forecast_original, label='Train Forecast', color='green')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(test, label='Test Data')\n",
    "plt.plot(test_forecast_original, label='Test Forecast', color='red')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mae_train = mean_absolute_error(train[24:], train_forecast_original)\n",
    "mae_test = mean_absolute_error(test, test_forecast_original)\n",
    "print(f\"Train mae: {mae_train}\")\n",
    "print(f\"Test mae: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.to_datetime(train.index.max()).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(train.iloc[24:], train_forecast_original))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forecast_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
